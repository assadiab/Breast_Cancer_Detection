# tests/test_attention_detailed.py
import os

os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
import sys
from pathlib import Path

# Ajouter le chemin des mod√®les
models_path = Path(__file__).parent.parent / "models"
sys.path.append(str(models_path))

from models.multi_expert import CrossModalFusion, OptimizedMultiExpertModel


def visualize_attention_matrix():
    print("üîç MATRICE D'ATTENTION D√âTAILL√âE")
    print("=" * 60)

    device = torch.device("mps")

    # Cr√©er un custom fusion module avec hook pour capturer l'attention
    class FusionWithHook(CrossModalFusion):
        def __init__(self, *args, **kwargs):
            super().__init__(*args, **kwargs)
            self.attention_weights = None

        def forward(self, embeddings):
            # Hook pour capturer les poids d'attention
            def hook(module, input, output):
                self.attention_weights = output[1]  # attention weights

            # Register hook
            handle = self.cross_attn.register_forward_hook(hook)

            # Forward normal
            result = super().forward(embeddings)

            # Remove hook
            handle.remove()

            return result

    # Mod√®le avec hook
    fusion = FusionWithHook(embed_dim=256, num_heads=4, num_experts=4).to(device)
    fusion.eval()

    # Simuler des embeddings d'experts
    batch_size = 2
    expert_embeddings = torch.randn(batch_size, 4, 256, device=device)

    with torch.no_grad():
        pred, gates = fusion(expert_embeddings)

    if fusion.attention_weights is not None:
        print(f"üéØ Matrice d'attention captur√©e: {fusion.attention_weights.shape}")

        # Visualiser pour le premier √©chantillon, premi√®re t√™te
        expert_names = ["Detector", "Texture", "Context", "Segment"]

        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        axes = axes.flatten()

        for head in range(4):  # 4 t√™tes d'attention
            attn_matrix = fusion.attention_weights[0, head].cpu().numpy()

            im = axes[head].imshow(attn_matrix, cmap='Blues', vmin=0, vmax=1)
            axes[head].set_title(f'T√™te d\'Attention {head + 1}')
            axes[head].set_xticks(range(4))
            axes[head].set_yticks(range(4))
            axes[head].set_xticklabels(expert_names, rotation=45)
            axes[head].set_yticklabels(expert_names)

            # Annoter les valeurs
            for i in range(4):
                for j in range(4):
                    axes[head].text(j, i, f'{attn_matrix[i, j]:.2f}',
                                    ha='center', va='center', fontsize=8)

        plt.suptitle('Matrices d\'Attention - Qui √©coute qui?', fontsize=16)
        plt.tight_layout()
        plt.savefig('attention_matrices_detailed.png', dpi=150, bbox_inches='tight')
        print("üìà Matrices d'attention sauvegard√©es: attention_matrices_detailed.png")

    return fusion.attention_weights


def test_expert_specialization():
    """Test avec des experts simul√©s ayant des sp√©cialisations diff√©rentes"""
    print("\n" + "=" * 60)
    print("üé≠ TEST AVEC EXPERTS SP√âCIALIS√âS")
    print("=" * 60)

    device = torch.device("mps")
    fusion = CrossModalFusion(embed_dim=256, num_heads=4, num_experts=4).to(device)
    fusion.eval()

    # Cr√©er des embeddings simul√©s avec des "patterns" diff√©rents
    batch_size = 3

    # Cas 1: Tous les experts similaires
    similar_experts = torch.randn(1, 4, 256, device=device).repeat(batch_size, 1, 1)

    # Cas 2: Experts tr√®s diff√©rents
    diverse_experts = torch.randn(batch_size, 4, 256, device=device)

    # Cas 3: Un expert dominant (simuler un cas o√π un expert est tr√®s important)
    dominant_expert = torch.randn(batch_size, 4, 256, device=device)
    dominant_expert[:, 1, :] += 5.0  # Rendre le Texture expert tr√®s actif

    test_cases = {
        "Experts similaires": similar_experts,
        "Experts diversifi√©s": diverse_experts,
        "Expert dominant (Texture)": dominant_expert
    }

    results = {}

    with torch.no_grad():
        for name, experts in test_cases.items():
            print(f"\nüî¨ {name}:")
            pred, gates = fusion(experts)

            print(f"  Gates: {[f'{g:.3f}' for g in gates[0].cpu().numpy()]}")
            print(f"  Pr√©diction: {pred[0].item():.4f}")

            results[name] = {
                'gates': gates.cpu().numpy(),
                'pred': pred.cpu().numpy()
            }

    return results


def analyze_real_model_attention():
    """Analyse l'attention sur le vrai mod√®le avec donn√©es r√©elles"""
    print("\n" + "=" * 60)
    print("üß† ANALYSE ATTENTION MOD√àLE R√âEL")
    print("=" * 60)

    device = torch.device("mps")
    model = OptimizedMultiExpertModel(embed_dim=256).to(device)
    model.eval()

    # Diff√©rents types d'images simul√©es
    print("üé≠ Test avec diff√©rents types d'images simul√©es:")

    # 1. Images "normales" (bruit al√©atoire)
    normal_images = torch.randn(2, 1, 512, 512, device=device)
    normal_lowres = torch.randn(2, 1, 224, 224, device=device)

    # 2. Images avec texture forte (simuler anomalies)
    textured_images = torch.randn(2, 1, 512, 512, device=device)
    textured_images += torch.randn_like(textured_images) * 2  # Plus de texture

    with torch.no_grad():
        # Test images normales
        pred1, gates1, emb1 = model(normal_images, normal_lowres)
        print(f"\nüìä Images 'normales':")
        expert_names = ["Detector", "Texture", "Context", "Segment"]
        for i, name in enumerate(expert_names):
            print(f"  {name}: {gates1[0][i].item():.3f}")

        # Test images textur√©es
        pred2, gates2, emb2 = model(textured_images, normal_lowres)
        print(f"\nüìä Images 'textur√©es' (anomalies):")
        for i, name in enumerate(expert_names):
            print(f"  {name}: {gates2[0][i].item():.3f}")

        # Comparaison
        print(f"\nüìà Diff√©rence gates (textur√© - normal):")
        for i, name in enumerate(expert_names):
            diff = gates2[0][i].item() - gates1[0][i].item()
            print(f"  {name}: {diff:+.3f}")


if __name__ == "__main__":
    # 1. Matrice d'attention d√©taill√©e
    attention_weights = visualize_attention_matrix()

    # 2. Test sp√©cialisation experts
    results = test_expert_specialization()

    # 3. Analyse mod√®le r√©el
    analyze_real_model_attention()

    print("\n" + "=" * 60)
    print("üéâ ANALYSE TERMIN√âE!")
    print("=" * 60)