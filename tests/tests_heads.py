# tests/tests_heads.py
import os

os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

import torch
import torch.nn as nn
import numpy as np
import sys
from pathlib import Path

# Ajouter le chemin des modÃ¨les
models_path = Path(__file__).parent.parent / "models"
sys.path.append(str(models_path))

try:
    from models.multi_expert import (
        EfficientDetectorHead,
        EfficientTextureHead,
        EfficientContextHead,
        EfficientSegmentHead,
        OptimizedMultiExpertModel
    )

    print("âœ… Modules chargÃ©s avec succÃ¨s")
except ImportError as e:
    print(f"âŒ Erreur import: {e}")
    print("VÃ©rifiez le chemin vers multi_expert_optimized.py")
    sys.exit(1)


class HeadsTester:
    def __init__(self, device="mps"):
        self.device = torch.device(device)
        print(f"ğŸ–¥ï¸  Device utilisÃ©: {self.device}")
        self.embed_dim = 256

        # Initialiser les tÃªtes
        print("ğŸ§  Initialisation des tÃªtes...")
        self.detector_head = EfficientDetectorHead(out_dim=self.embed_dim)
        self.texture_head = EfficientTextureHead(out_dim=self.embed_dim, use_checkpoint=False)
        self.context_head = EfficientContextHead(out_dim=self.embed_dim, use_checkpoint=False)
        self.segment_head = EfficientSegmentHead(out_dim=self.embed_dim)

        # Mode Ã©valuation
        self.detector_head.eval()
        self.texture_head.eval()
        self.context_head.eval()
        self.segment_head.eval()

        # DÃ©placer sur device
        self.detector_head.to(self.device)
        self.texture_head.to(self.device)
        self.context_head.to(self.device)
        self.segment_head.to(self.device)
        print("âœ… TÃªtes dÃ©placÃ©es sur device")

    def create_dummy_batch(self, batch_size=2, high_res=(512, 512), low_res=(224, 224)):
        """CrÃ©e un batch dummy pour tester"""
        high_res_images = torch.randn(batch_size, 1, *high_res).to(self.device)
        low_res_images = torch.randn(batch_size, 1, *low_res).to(self.device)
        return high_res_images, low_res_images

    def test_individual_heads(self):
        """Teste chaque tÃªte individuellement"""
        print("\nğŸ§ª TEST DES TÃŠTES INDIVIDUELLES")
        print("=" * 60)

        high_res, low_res = self.create_dummy_batch()

        # Test Detector Head
        print("\n1. ğŸ¯ DETECTOR HEAD")
        try:
            with torch.no_grad():
                det_emb = self.detector_head(high_res)
            print(f"   âœ… Input: {high_res.shape} -> Output: {det_emb.shape}")
            print(f"   ğŸ“Š Stats - Mean: {det_emb.mean().item():.4f}, Std: {det_emb.std().item():.4f}")
        except Exception as e:
            print(f"   âŒ Erreur: {e}")

        # Test Texture Head
        print("\n2. ğŸ” TEXTURE HEAD (EfficientNet-B0)")
        try:
            with torch.no_grad():
                tex_emb = self.texture_head(high_res)
            print(f"   âœ… Input: {high_res.shape} -> Output: {tex_emb.shape}")
            print(f"   ğŸ“Š Stats - Mean: {tex_emb.mean().item():.4f}, Std: {tex_emb.std().item():.4f}")

        except Exception as e:
            print(f"   âŒ Erreur: {e}")

        # Test Context Head
        print("\n3. ğŸŒ CONTEXT HEAD (Swin-Tiny)")
        try:
            with torch.no_grad():
                ctx_emb = self.context_head(low_res)
            print(f"   âœ… Input: {low_res.shape} -> Output: {ctx_emb.shape}")
            print(f"   ğŸ“Š Stats - Mean: {ctx_emb.mean().item():.4f}, Std: {ctx_emb.std().item():.4f}")

        except Exception as e:
            print(f"   âŒ Erreur: {e}")

        # Test Segment Head
        print("\n4. ğŸ¨ SEGMENT HEAD (U-Net light)")
        try:
            with torch.no_grad():
                seg_emb = self.segment_head(high_res)
            print(f"   âœ… Input: {high_res.shape} -> Output: {seg_emb.shape}")
            print(f"   ğŸ“Š Stats - Mean: {seg_emb.mean().item():.4f}, Std: {seg_emb.std().item():.4f}")
        except Exception as e:
            print(f"   âŒ Erreur: {e}")

    def test_full_model(self):
        """Test du modÃ¨le complet avec fusion"""
        print("\n" + "=" * 60)
        print("ğŸš€ TEST MODÃˆLE COMPLET AVEC FUSION")
        print("=" * 60)

        high_res, low_res = self.create_dummy_batch()

        # CrÃ©er modÃ¨le complet
        full_model = OptimizedMultiExpertModel(
            embed_dim=self.embed_dim,
            use_checkpoint=False
        ).to(self.device)
        full_model.eval()

        try:
            with torch.no_grad():
                preds, gates, embeddings = full_model(high_res, low_res)

            print(f"âœ… ModÃ¨le complet fonctionnel!")
            print(f"ğŸ“¥ Input high_res: {high_res.shape}")
            print(f"ğŸ“¥ Input low_res: {low_res.shape}")
            print(f"ğŸ“¤ Output preds: {preds.shape} (probabilitÃ©s)")
            print(f"ğŸ“¤ Output gates: {gates.shape} (poids experts)")
            print(f"ğŸ“¤ Output embeddings: {embeddings.shape} (features)")

            # Analyser les gates (attention weights)
            print(f"\nğŸšï¸  GATES (poids des experts):")
            expert_names = ["Detector", "Texture", "Context", "Segment"]
            for i, name in enumerate(expert_names):
                gate_mean = gates[:, i].mean().item()
                print(f"   {name}: {gate_mean:.4f}")

            # VÃ©rifier prÃ©dictions
            print(f"\nğŸ”® PRÃ‰DICTIONS:")
            print(f"   Range: [{preds.min().item():.4f}, {preds.max().item():.4f}]")
            print(f"   Mean: {preds.mean().item():.4f}")

        except Exception as e:
            print(f"âŒ Erreur modÃ¨le complet: {e}")
            import traceback
            traceback.print_exc()


def main():
    """Lance tous les tests"""
    print("ğŸ§ª DÃ‰MARRAGE DES TESTS DES TÃŠTES MULTI-EXPERTS")

    # VÃ©rifier MPS
    if not torch.backends.mps.is_available():
        print("âŒ MPS non disponible - utilisation CPU")
        device = "cpu"
    else:
        device = "mps"
        print("âœ… MPS disponible")

    tester = HeadsTester(device=device)

    # Test individuel des tÃªtes
    tester.test_individual_heads()

    # Test modÃ¨le complet
    tester.test_full_model()

    print("\n" + "=" * 60)
    print("ğŸ‰ TESTS TERMINÃ‰S!")
    print("=" * 60)


if __name__ == "__main__":
    main()